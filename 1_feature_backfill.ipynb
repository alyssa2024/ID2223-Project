{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82622ee3",
   "metadata": {
    "id": "82622ee3"
   },
   "source": [
    "## <span style=\"color:#ff5f27\">ğŸ“ Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "kkvpsHNjyrra",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34783,
     "status": "ok",
     "timestamp": 1767717940875,
     "user": {
      "displayName": "alyssa",
      "userId": "18151921927230202476"
     },
     "user_tz": -60
    },
    "id": "kkvpsHNjyrra",
    "outputId": "49355b47-0bb8-463f-ac0f-3c87f0344ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m765.9/765.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m587.2/587.2 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m258.6/258.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for avro (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for twofish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q hopsworks rdflib sentence-transformers pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gCEqcKWw3nb_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "error",
     "timestamp": 1767715315868,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "gCEqcKWw3nb_",
    "outputId": "eb72bbe7-16b9-4a85-b6d1-9a1e691a9193"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4168713861.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhopsworks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhsfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbeddingIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from hsfs.embedding import EmbeddingIndex\n",
    "\n",
    "from functions.zotero_parser import ZoteroRDFParser\n",
    "from functions.PDF_extractor import ContentProcessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oGPa_qOH0yLQ",
   "metadata": {
    "id": "oGPa_qOH0yLQ"
   },
   "source": [
    "## <span style=\"color:#ff5f27\"> Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1oM-3ymz1F8",
   "metadata": {
    "id": "h1oM-3ymz1F8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# PROJECT_NAME = \"ä½ çš„Hopsworksé¡¹ç›®å\"\n",
    "\n",
    "# ZOTERO_ROOT = \"/content/ID2223-Project/zotero\"\n",
    "\n",
    "# RDF_PATH = f\"{ZOTERO_ROOT}/location privacy.rdf\"\n",
    "# BASE_DIR = ZOTERO_ROOT\n",
    "\n",
    "# MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# MIN_FULLTEXT_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S-TH_b7bA8GT",
   "metadata": {
    "id": "S-TH_b7bA8GT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from config import (\n",
    "    RDF_PATH,\n",
    "    BASE_DIR,\n",
    "    EMBEDDING_MODEL_NAME,\n",
    "    MIN_FULLTEXT_LEN,\n",
    "    HOPSWORKS_PROJECT,\n",
    "    HOPSWORKS_API_KEY,\n",
    "    META_FG_NAME,\n",
    "    META_FG_VERSION,\n",
    "    FULLTEXT_FG_NAME,\n",
    "    FULLTEXT_FG_VERSION,\n",
    "    META_FV_NAME,\n",
    "    FULLTEXT_FV_NAME\n",
    ")\n",
    "\n",
    "os.environ[\"HOPSWORKS_API_KEY\"] = \"1QJZ515qO3Hl6pwr.Kr6HwXJ5SbnYV6TeEyAEyDGsV31Is9rryhZUyvRjamJjodvONIodYhBskNcZxHAz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f783e27e",
   "metadata": {
    "id": "f783e27e"
   },
   "source": [
    "## <span style=\"color:#ff5f27\">ğŸ§¬ Metadata and Text Extraction, Embedding Creation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xEaWcXPP4oN8",
   "metadata": {
    "id": "xEaWcXPP4oN8"
   },
   "outputs": [],
   "source": [
    "# === Cell 3: Parse Zotero RDF ===\n",
    "\n",
    "parser = ZoteroRDFParser(\n",
    "    rdf_file_path=RDF_PATH,\n",
    "    base_attachment_dir=BASE_DIR\n",
    ")\n",
    "\n",
    "papers = parser.parse()\n",
    "\n",
    "print(f\"Parsed {len(papers)} papers.\")\n",
    "papers[:2]  # å¿«é€Ÿ sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318Tc5AI4t_T",
   "metadata": {
    "id": "318Tc5AI4t_T"
   },
   "outputs": [],
   "source": [
    "# === Cell 4: Extract Full Text from Attachments ===\n",
    "\n",
    "metadata_rows = []\n",
    "fulltext_rows = []\n",
    "\n",
    "for paper in papers:\n",
    "    full_text = \"\"\n",
    "\n",
    "    for attach in paper[\"attachments\"]:\n",
    "        full_path = os.path.join(BASE_DIR, attach[\"path\"])\n",
    "        content = ContentProcessor.read_file(full_path, attach[\"type\"])\n",
    "\n",
    "        if len(content) > MIN_FULLTEXT_LEN:\n",
    "            full_text = content\n",
    "            break  # åªå–ä¸€ä¸ªå¯è¯»æ­£æ–‡\n",
    "\n",
    "    # Zotero æ²¡æ‘˜è¦ â†’ ä»å…¨æ–‡å…œåº•\n",
    "    if not paper[\"abstract\"] and full_text:\n",
    "        fallback_abs = ContentProcessor.extract_abstract_fallback(full_text)\n",
    "        if fallback_abs:\n",
    "            paper[\"abstract\"] = fallback_abs\n",
    "\n",
    "    # --- Metadata Row ---\n",
    "    metadata_rows.append({\n",
    "        \"paper_id\": paper[\"id\"],\n",
    "        \"title\": paper[\"title\"],\n",
    "        \"abstract\": paper[\"abstract\"],\n",
    "        \"authors\": paper[\"authors\"],\n",
    "        \"year\": paper[\"year\"],\n",
    "        \"category\": paper[\"category\"],\n",
    "        \"combined_text\": (\n",
    "            f\"Title: {paper['title']}\\n\"\n",
    "            f\"Category: {paper['category']}\\n\"\n",
    "            f\"Abstract: {paper['abstract']}\"\n",
    "        )\n",
    "    })\n",
    "\n",
    "    # --- Full-text Rows ---\n",
    "    if full_text:\n",
    "        chunks = ContentProcessor.chunk_text(full_text)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            fulltext_rows.append({\n",
    "                \"paper_id\": paper[\"id\"],\n",
    "                \"chunk_index\": i,\n",
    "                \"content\": chunk,\n",
    "                \"year\": paper[\"year\"]\n",
    "            })\n",
    "\n",
    "print(f\"Metadata rows: {len(metadata_rows)}\")\n",
    "print(f\"Fulltext chunks: {len(fulltext_rows)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bced31",
   "metadata": {
    "id": "d2bced31"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> ğŸ”® Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf764d",
   "metadata": {
    "id": "7caf764d"
   },
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "from config import HOPSWORKS_PROJECT, HOPSWORKS_API_KEY\n",
    "# project = hopsworks.login()\n",
    "\n",
    "project = hopsworks.login(\n",
    "        project=HOPSWORKS_PROJECT,\n",
    "        api_key_value=HOPSWORKS_API_KEY\n",
    "    )\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9ac69",
   "metadata": {
    "id": "0ed9ac69"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> ğŸª„ Feature Group Creation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e486b",
   "metadata": {
    "id": "9f5e486b"
   },
   "outputs": [],
   "source": [
    "from hsfs import embedding\n",
    "\n",
    "# # Create the Embedding Index\n",
    "# emb = embedding.EmbeddingIndex()\n",
    "\n",
    "# emb.add_embedding(\n",
    "#     \"embeddings\",\n",
    "#     model.get_sentence_embedding_dimension(),\n",
    "# )\n",
    "\n",
    "# # Get or create the 'documents_fg' feature group\n",
    "# documents_fg = fs.get_or_create_feature_group(\n",
    "#     name=\"documents_fg\",\n",
    "#     description='Information from various files, presenting details like file names, source links, and structured text excerpts from different pages and paragraphs.',\n",
    "#     version=1,\n",
    "#     primary_key=['context_id'],\n",
    "#     online_enabled=True,\n",
    "#     embedding_index=emb,\n",
    "# )\n",
    "\n",
    "# documents_fg.insert(df_text_processed)\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "df_meta = pd.DataFrame(metadata_rows)\n",
    "df_meta[\"embedding\"] = df_meta[\"combined_text\"].apply(\n",
    "    lambda x: model.encode(x).tolist()\n",
    ")\n",
    "\n",
    "meta_fg = fs.get_or_create_feature_group(\n",
    "    name=\"zotero_meta_fg\",\n",
    "    version=1,\n",
    "    description=\"Paper Metadata (Title + Abstract)\",\n",
    "    primary_key=[\"paper_id\"],\n",
    "    online_enabled=True,\n",
    "    embedding_index=EmbeddingIndex()\n",
    ")\n",
    "\n",
    "meta_fg.insert(df_meta)\n",
    "\n",
    "print(\"âœ… Metadata Feature Group uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32b548",
   "metadata": {
    "id": "6e32b548"
   },
   "outputs": [],
   "source": [
    "if fulltext_rows:\n",
    "    df_text = pd.DataFrame(fulltext_rows)\n",
    "    df_text[\"embedding\"] = df_text[\"content\"].apply(\n",
    "        lambda x: model.encode(x).tolist()\n",
    "    )\n",
    "\n",
    "    text_fg = fs.get_or_create_feature_group(\n",
    "        name=\"zotero_fulltext_fg\",\n",
    "        version=1,\n",
    "        description=\"Paper Full-text Chunks\",\n",
    "        primary_key=[\"paper_id\", \"chunk_index\"],\n",
    "        online_enabled=True,\n",
    "        embedding_index=EmbeddingIndex()\n",
    "    )\n",
    "\n",
    "    text_fg.insert(df_text)\n",
    "    print(\"âœ… Full-text Feature Group uploaded.\")\n",
    "else:\n",
    "    print(\"âš ï¸ No full-text chunks found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a9ed6",
   "metadata": {
    "id": "d39a9ed6"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">ğŸª„ Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bc2f0",
   "metadata": {
    "id": "7a7bc2f0"
   },
   "outputs": [],
   "source": [
    "# # Get or create the 'documents' feature view\n",
    "# feature_view = fs.get_or_create_feature_view(\n",
    "#     name=\"documents\",\n",
    "#     version=1,\n",
    "#     description='Chunked context for RAG system',\n",
    "#     query=documents_fg.select([\"file_name\", \"file_link\", \"page_number\", \"paragraph\", \"text\"]),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OJ6koRqW6KsN",
   "metadata": {
    "id": "OJ6koRqW6KsN"
   },
   "outputs": [],
   "source": [
    "# === Feature View: Paper-level Metadata ===\n",
    "\n",
    "paper_meta_fv = fs.get_or_create_feature_view(\n",
    "    name=\"zotero_papers\",\n",
    "    version=1,\n",
    "    description=\"Paper-level metadata for literature search and selection\",\n",
    "    query=meta_fg.select([\n",
    "        \"paper_id\",\n",
    "        \"title\",\n",
    "        \"abstract\",\n",
    "        \"authors\",\n",
    "        \"year\",\n",
    "        \"category\"\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bj3WyVOX6MQS",
   "metadata": {
    "id": "Bj3WyVOX6MQS"
   },
   "outputs": [],
   "source": [
    "# === Feature View: Full-text Chunks for RAG ===\n",
    "\n",
    "paper_chunks_fv = fs.get_or_create_feature_view(\n",
    "    name=\"zotero_chunks\",\n",
    "    version=1,\n",
    "    description=\"Chunked full-text context for RAG and paper reading agent\",\n",
    "    query=text_fg.select([\n",
    "        \"paper_id\",\n",
    "        \"chunk_index\",\n",
    "        \"content\",\n",
    "        \"year\"\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b9a5f",
   "metadata": {
    "id": "708b9a5f"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/alyssa2024/ID2223-Project/blob/main/1_feature_backfill.ipynb",
     "timestamp": 1767715450010
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
