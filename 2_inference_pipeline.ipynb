{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75a9c7f",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9836097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Imports ===\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hopsworks\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HF_API_KEY\"] = \"\"\n",
    "os.environ[\"SILICONFLOW_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1113fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 21:06:33,974 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2026-01-11 21:06:33,978 INFO: Initializing external client\n",
      "2026-01-11 21:06:33,978 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-11 21:06:35,383 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286333\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Connect to Hopsworks ===\n",
    "\n",
    "from config import HOPSWORKS_API_KEY\n",
    "# project = hopsworks.login()\n",
    "\n",
    "project = hopsworks.login(\n",
    "        # project=HOPSWORKS_PROJECT,\n",
    "        api_key_value=HOPSWORKS_API_KEY\n",
    "    )\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b12dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Load Feature Views ===\n",
    "\n",
    "metadata_fv = fs.get_feature_view(\n",
    "    name=\"paper_metadata_fv_2\",\n",
    "    version=3,\n",
    ")\n",
    "\n",
    "chunk_fv = fs.get_feature_view(\n",
    "    name=\"paper_chunk_fv_2\",\n",
    "    version=3,\n",
    ")\n",
    "\n",
    "metadata_fv.init_serving(1)\n",
    "chunk_fv.init_serving(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf9e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 21:06:44,745 INFO: Use pytorch device_name: cpu\n",
      "2026-01-11 21:06:44,745 INFO: Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: Load Embedding Model ===\n",
    "sentence_transformer = SentenceTransformer(\n",
    "    config.EMBEDDING_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b2c31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: Similarity Search Engine ===\n",
    "\n",
    "from functions.similarity_search import SimilaritySearchEngine\n",
    "\n",
    "search_engine = SimilaritySearchEngine(\n",
    "    embedding_model=sentence_transformer,\n",
    "    metadata_feature_view=metadata_fv,\n",
    "    chunk_feature_view=chunk_fv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e5cf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Context Builder ===\n",
    "\n",
    "from functions.context_builder import ContextBuilder\n",
    "\n",
    "context_builder = ContextBuilder(\n",
    "    max_tokens=2000,\n",
    "    max_chunks=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f7e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Prompt Synthesizer ===\n",
    "\n",
    "# from functions.prompt_synthesis import PromptSynthesizer\n",
    "# prompt_synthesizer = PromptSynthesizer()\n",
    "\n",
    "from functions.prompt_synthesis_debug import DebugPromptSynthesizer\n",
    "\n",
    "prompt_synthesizer = DebugPromptSynthesizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29faaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: MCP Dispatcher ===\n",
    "\n",
    "from functions.mcp_dispatcher import MCPDispatcher\n",
    "\n",
    "mcp_dispatcher = MCPDispatcher(\n",
    "    search_engine=search_engine\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e0c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: Agentic Inference ===\n",
    "\n",
    "from functions.agent_loop import AgenticInference\n",
    "from functions.llm_wrapper import LLMWrapper  \n",
    "\n",
    "# llm = LLMWrapper(\n",
    "#     model_name_or_path=\"mistralai/Mistral-7B-v0.1\"  \n",
    "# )# local llm\n",
    "llm = LLMWrapper(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    base_url=\"http://api.siliconflow.cn/v1/\",\n",
    "    api_key=os.getenv(\"SILICONFLOW_API_KEY\"),\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "agent = AgenticInference(\n",
    "    llm=llm,\n",
    "    search_engine=search_engine,\n",
    "    context_builder=context_builder,\n",
    "    prompt_synthesizer=prompt_synthesizer,\n",
    "    mcp_dispatcher=mcp_dispatcher,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eb23e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "2026-01-11 21:06:48,503 INFO: HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2026-01-11 21:06:48,517 INFO: HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 21:06:48,869 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a55df268434e3196e52f7178d8afc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 21:07:40,327 WARNING: POST https://15.235.49.70:9200/1286333__embedding_default_project_embedding_0/_search [status:N/A request:0.000s]\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\opensearchpy\\connection\\http_urllib3.py\", line 264, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1712, in urlopen\n",
      "    conn = self._get_conn(timeout=pool_timeout, heb_timeout=timeout_obj)\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 684, in _get_conn\n",
      "    raise ClosedPoolError(self, \"Pool is closed.\")\n",
      "urllib3.exceptions.ClosedPoolError: HTTPSConnectionPool(host='15.235.49.70', port=9200): Pool is closed.\n",
      "2026-01-11 21:07:40,329 WARNING: POST https://15.235.49.70:9200/1286333__embedding_default_project_embedding_0/_search [status:N/A request:0.000s]\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\opensearchpy\\connection\\http_urllib3.py\", line 264, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1712, in urlopen\n",
      "    conn = self._get_conn(timeout=pool_timeout, heb_timeout=timeout_obj)\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 684, in _get_conn\n",
      "    raise ClosedPoolError(self, \"Pool is closed.\")\n",
      "urllib3.exceptions.ClosedPoolError: HTTPSConnectionPool(host='15.235.49.70', port=9200): Pool is closed.\n",
      "2026-01-11 21:07:40,332 WARNING: POST https://15.235.49.70:9200/1286333__embedding_default_project_embedding_0/_search [status:N/A request:0.000s]\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\opensearchpy\\connection\\http_urllib3.py\", line 264, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1712, in urlopen\n",
      "    conn = self._get_conn(timeout=pool_timeout, heb_timeout=timeout_obj)\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 684, in _get_conn\n",
      "    raise ClosedPoolError(self, \"Pool is closed.\")\n",
      "urllib3.exceptions.ClosedPoolError: HTTPSConnectionPool(host='15.235.49.70', port=9200): Pool is closed.\n",
      "2026-01-11 21:07:40,334 WARNING: POST https://15.235.49.70:9200/1286333__embedding_default_project_embedding_0/_search [status:N/A request:0.000s]\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\opensearchpy\\connection\\http_urllib3.py\", line 264, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1712, in urlopen\n",
      "    conn = self._get_conn(timeout=pool_timeout, heb_timeout=timeout_obj)\n",
      "  File \"e:\\anaconda3\\envs\\aq\\lib\\site-packages\\urllib3\\connectionpool.py\", line 684, in _get_conn\n",
      "    raise ClosedPoolError(self, \"Pool is closed.\")\n",
      "urllib3.exceptions.ClosedPoolError: HTTPSConnectionPool(host='15.235.49.70', port=9200): Pool is closed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53307bb0cdea40dd8eaa4cb82ff2d7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAPER METADATA: {'IZB6XZRC': {'title': 'Synthetic Time Series Data Generation for Healthcare Applications: A PCG Case Study', 'abstract': 'The generation of high-quality medical time series data is essential for advancing healthcare diagnostics and safeguarding patient privacy. Specifically, synthesizing realistic phonocardiogram (PCG) signals offers significant potential as a cost-effective and efficient tool for cardiac disease pre-screening. Despite its potential, the synthesis of PCG signals for this specific application received limited attention in research. In this study, we employ and compare three state-of-the-art generative models from different categories — WaveNet, DoppelGANger, and DiffWave — to generate high-quality PCG data. We use data from the George B. Moody PhysioNet Challenge 2022. Our methods are evaluated using various metrics widely used in the previous literature in the domain of time series data generation, such as mean absolute error and maximum mean discrepancy. Our results demonstrate that the generated PCG data closely resembles the original datasets, indicating the effectiveness of our generative models in producing realistic synthetic PCG data. In our future work, we plan to incorporate this method into a data augmentation pipeline to synthesize abnormal PCG signals with heart murmurs, in order to address the current scarcity of abnormal data. We hope to improve the robustness and accuracy of diagnostic tools in cardiology, enhancing their effectiveness in detecting heart murmurs.'}, 'PDU98SKK': {'title': 'A Novel Approach for Long ECG Synthesis Utilize Diffusion Probabilistic Model', 'abstract': 'Deep neural networks (DNNs) have gained popularity and outperformed in ECG signal classification and detection challenges. However, the paucity of data for abnormal rhythms such as the atrioventricular block, ventricular tachycardia, or supraventricular tachycardia has restricted DNN performance. ECG synthesis has lately been regarded as a new efficient approach to supplement imbalanced training data to overcome DNN issues and replace an ECG simulator. Most previous ECG-creation studies have focused on constructing a simple QRS complex, which cannot depict the characteristics of an ECG rhythm composed of numerous QRS complexes. This study addresses lengthy ECG synthesis using the diffusion probabilistic model, a class of generative models that has attracted a lot of attention lately. Our proposal is efficient, flexible, and lightweight by using powerful DiffWave architecture as a baseline model. This approach has revealed the capability to generate long ECG signals similar to those obtained from patients. The Physionet dataset, including MIT-BIH Arrhythmia and MIT-BIH Atrial Fibrillation Databases, is applied to train and test our models. Consequently, we produced 10-second ECGs with several rhythms that were not visible in earlier investigations. The proposal outperforms the most satisfactory research in ECGs when comparing our high-quality synthesized data with actual signals on DNN models. Furthermore, our method also offers a novel technique to investigate electrocardiogram data without using an ECG simulator.'}, 'T55ZK2Y7': {'title': 'PCG Signal Acquisition and Classification for Heart Failure Detection: Recent Advances and Implementation of Memory-Efficient Classifiers for Edge Computing-Based Wearable Devices', 'abstract': 'Conventional diagnostic tools for cardiovascular diseases usually employ expensive instrumentation and require specialized medical staff. An inexpensive and non-invasive alternative is the phonocardiogram (PCG). This paper presents the development of classifiers for binary (Normal/Pathological) and multiclass classifications of PCG signals. The latter discerns between a subset of heart diseases (mitral valve prolapse (MVP), coronary disease (CAD), and benign murmurs (Benign)). Two balanced datasets were created from the Physionet 2016/CinC database, consisting of 10104 and 13136 5-s frames. A custom preprocessing chain includes denoising, normalizing, and splitting the PCG signals, making them suitable to extract the scalar features set, constituting the training and test set. Several ML/DL models (e.g., SVMs (Support Vector Machines), k-NNs (k-Nearest Neighbors), and NNs (Neural Networks)) were trained and tested to classify the PCG signals. For binary classification, three different NNs have reached 96.0%, 95.9%, and 93.4% accuracy, and 95.9%, 96.0%, and 93.3% F1-scores, respectively. However, k-NN classifiers provide higher accuracy (up to 98.7%) than NNs but require much larger memory (up to 11 MB). As for the multiclass classification, three custom NNs have achieved 96.0%, 95.8%, and 94.7% accuracy with 735 kB max memory occupation. The developed classifiers provide a good balance between complexity and performance, with the latter not dependent on signal quality. In the feature engineering phase, the heart sound segmentation was not performed to make the classifiers suitable for resource-limited platforms.'}, '5TCMVED9': {'title': 'A Latent Diffusion Model for Heart Sound Synthesis', 'abstract': 'There are already many analyses of heart sounds used to develop diagnostic systems for the heart condition. However, the existing heart sound database state is not sufficient to train a large number of deep learning models and is not balanced -- the normal heart sounds are always more present than abnormal heart sounds. Hence, we are interested in algorithms that can generate heart sounds as they can enhance the current database state. We enter the field of large-scale modelling in medical synthesis by proposing a latent diffusion model for heart sound generation, which can generate highly realistic heart sounds. We further guide the synthesis process through text prompts and labels, revealing the research field of prompted heart sound synthesis. In terms of experimental results, our proposed method achieves good results compared to existing mathematical models. At the same time, when the generated audio is used as an unlabelled dataset in semi-supervised learning, it shows an improvement effect on the classification model. This indicates that the heart sounds generated by the diffusion model bear great value.'}, 'R7JAHFY6': {'title': 'ECG Generation Based on Denoising Diffusion Probabilistic Models', 'abstract': 'Arrhythmia diseases seriously damage people’s life and health, and identifying abnormal points in ECG signals by deep neural networks is an effective method for detecting arrhythmias. However, their accuracy is often limited by the biased data distribution of the training set, and a large number of labeled ECG signals are usually harder to obtain. Therefore, this paper proposes to synthesize virtual heart beat data by denoising diffusion probability model (DDPM) based on the MIT-BIH arrhythmia database to complement the real data. Three different methods for generating heartbeat signals are also used, which are (i) generating heartbeat signals directly, (ii) generating time-frequency maps of heartbeats and transforming them into heartbeat signals, and (iii) generating sub-signals of heartbeats and fusing them into complete heartbeat signals. Regarding the evaluation of the synthesized signals, we compare the advantages and disadvantages of the three heartbeat generation methods by four metrics: DTW, PCC, ED and KLD. The experimental results showed that the optimum values of 4.37, 17.09, 0.972 and 0.0094 were obtained for ED, DTW of method (i) and PCC, KLD of method (iii), respectively.'}}\n",
      "=== CONTEXT BUNDLE ===\n",
      "{'items': [{'source_id': 'IZB6XZRC#chunk-0', 'paper_id': 'IZB6XZRC', 'title': 'Synthetic Time Series Data Generation for Healthcare Applications: A PCG Case Study', 'content': 'Synthetic Time Series Data Generation for Healthcare Applications: A PCG Case Study Ainaz Jamshidi Dept. of Information Systems University of Maryland Baltimore County, USA ainazj1@umbc.edu Muhammad Arif Dept. of Information Systems Colorado State University, USA muhammad.arif@csupueblo.edu Sabir Ali Kalhoro Dept. of Electrical Engineering North Dakota State University, USA Sabir13es66@gmail.com Alexander Gelbukh Dept. of Computing Research Center Instituto Polit´ecnico Nacional, Mexico gelbukh@cic.ipn.mx Abstract—The generation of high-quality medical time series data is essential for advancing healthcare diagnostics and safeguarding patient privacy. Specifically, synthesizing realistic phonocardiogram (PCG) signals offers significant potential as a cost-effective and efficient tool for cardiac disease pre-screening. Despite its potential, the synthesis of PCG signals for this specific application received limited attention in research. In this study, we employ and compare three state-of-the-art generative models from different categories — WaveNet, DoppelGANger, and DiffWave — to generate high-quality PCG data. We use data from the George B. Moody PhysioNet Challenge 2022. Our methods are evaluated using various metrics widely used in the previous literature in the domain of time series data generation, such as mean absolute error and maximum mean discrepancy.', 'score': 0.1}, {'source_id': 'IZB6XZRC#chunk-22', 'paper_id': 'IZB6XZRC', 'title': 'Synthetic Time Series Data Generation for Healthcare Applications: A PCG Case Study', 'content': 'According to these two metrics, both low scores indicate that the synthetic data generated by the model is very similar to the real data. TABLE II: DGAN’s Performance metrics in synthesizing PCG signals Metric JSD MMD Score 0.014 0.0001 C. DiffWave Performance on Synthesizing PCG signals In the case of the DiffWave model, we also evaluate its performance in generating healthy PCG signals based on the previously mentioned generative metrics. 1) t-SNE: The result of converting the real and synthetic data into two dimensions is depicted in Figure 3 for generating PCG sequences. It is easy to observe that there is a significant overlap between the synthetic and real data points. The majority of the data points, both synthetic (blue) and real (orange), are concentrated in a dense cluster without clear separation. 2) Discriminative Score: We train the RNN classifier described in Section 2 with the same hyperparameters Authorized licensed use limited to: KTH Royal Institute of Technology. Downloaded on September 25,2025 at 10:53:30 UTC from IEEE Xplore. Restrictions apply.', 'score': 0.2}, {'source_id': 'PDU98SKK#chunk-22', 'paper_id': 'PDU98SKK', 'title': 'A Novel Approach for Long ECG Synthesis Utilize Diffusion Probabilistic Model', 'content': 'A Novel Approach for Long ECG Synthesis Utilize Diffusion Probabilistic Model Conference’17, July 2017, Washington, DC, USA Figure 6: Comparison of 10-second ECG generation framework between our proposal with previous work [10, 22] Table 2: Accuracy of sinus family trained with MITDB by utilizing conditional Diffwave model Rhythm <60 bpm 60-80 bpm 81-100bpm >100bpm SBR 89% 9% 1% 0% NSR1 2% 91% 6% 1% NSR2 1% 6% 90% 3% STR 0% 1% 10% 89% NSR1: sinus rhythm 1, NSR2: sinus rhythm 2, STR: sinus tarchycardia The appropriate P and T waves should be present in a wellevaluated lengthy ECG signal. Fig. 6 compares the performance of our suggestions to that of other designs, such as S12-ECG-GAN [22] and TTS-GAN [10]. The fundamental issue with S12-ECG-GAN is that the generated 10-second signals are composed of the same representative beats. As a result, the signals created by this framework exhibit no variation in RR intervals or morphological properties. On the other hand, the signals produced by an ECG simulator can vary with different heart rates, but the morphological traits of a QRS complex are not changed in a 10-second signal. TTS-GAN appears to alleviate this issue; however, the P and T waveforms remain undesirable, with sharp peaks and irrational inclinations. In contrast, our proposal work has handled these challenges with varying heart rates and appropriate QRS-complex forms. P and T wave allocations and morphological traits are also clear and acceptable.', 'score': 0.25}, {'source_id': 'R7JAHFY6#chunk-12', 'paper_id': 'R7JAHFY6', 'title': 'ECG Generation Based on Denoising Diffusion Probabilistic Models', 'content': 'Figure 2. Comparison of various patterns of heartbeats in original data and data synthesized using Signal-diffusion. The blue lines indicate the original heartbeats, the green lines indicate the synthetic heartbeats. Table 2. Comparison of the fidelity of heartbeat synthesis. Method ED↓ DTW↓ PCC↑ KLD↓ Signal-diffusion 4.37 17.09 0.969 0.0234 Spectro-diffusion 9.08 74.83 0.643 0.0795 Wavelet-diffusion 4.39 20.93 0.972 0.0094 maps and transforming them, which may be due to the loss of information in the time-frequency transformation process. Meanwhile, synthesizing multi-scale sub-signals and fusing them also achieves better results, and this effect may be enhanced with the increase of signal scale. Synthesizing ECG signals through diffusion modeling may become a new direction to enrich the distribution of ECG data and solve the data privacy problem. Acknowledgments This work was funded by the National Natural Science Foundation of China (62171123, 62201144), and the National Key Research and Development Program of China (2023YFC3603600, 2022YFC2405600). References [1] Hammad M, Iliyasu AM, Subasi A, Ho ESL, Abd El-Latif AA. A multitier deep learning model for arrhythmia detection. IEEE Transactions on Instrumentation and Measurement 2021;70. ISSN 0018-9456. [2] Ma C, Wei S, Chen T, Zhong J, Liu Z, Liu C. Integration of results from convolutional neural network in a support vector machine for the detection of atrial fibrillation.', 'score': 0.3333333333333333}], 'stats': {'num_items': 4, 'unique_papers': 3}, 'token_usage': {'estimated_tokens': 801, 'max_tokens': 2000}}\n",
      "======================\n",
      "2026-01-11 21:08:03,243 INFO: HTTP Request: POST http://api.siliconflow.cn/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== RAW LLM OUTPUT ===\n",
      "{\n",
      "  \"decision\": \"answer\",\n",
      "  \"reasoning\": {\n",
      "    \"core_intent\": \"Identify the challenges in synthesizing PCG signals.\",\n",
      "    \"available_connections\": [\n",
      "      \"Evidence 0 supports the concept that synthesizing PCG signals is a challenging task due to the need for high-quality and realistic data generation.\",\n",
      "      \"Evidence 1 supports the concept that evaluating synthetic PCG data using metrics like JSD and MMD indicates the difficulty in achieving similarity with real data.\",\n",
      "      \"Evidence 2 supports the concept that generating ECG signals with varying heart rates and maintaining morphological traits is a challenge, which is relevant to PCG synthesis as both are cardiac signals.\",\n",
      "      \"Evidence 3 supports the concept that synthesizing heartbeat signals using diffusion models requires careful handling of time-frequency transformations and multi-scale sub-signals.\"\n",
      "    ],\n",
      "    \"inferences_made\": [\n",
      "      \"Applying general GAN theory to ECG domain suggests that maintaining morphological features and temporal consistency is a challenge in PCG synthesis.\",\n",
      "      \"The use of diffusion models for ECG synthesis implies similar challenges in PCG synthesis, such as preserving waveform characteristics and avoiding artifacts.\"\n",
      "    ],\n",
      "    \"rationale\": \"Despite fragmented evidence, the core intent of the question is addressed by the retrieved texts, which collectively highlight the challenges in generating realistic and high-quality PCG signals, including maintaining waveform fidelity, avoiding artifacts, and ensuring similarity to real data.\"\n",
      "  },\n",
      "  \"answer\": \"The challenge to synthesize PCG signals lies in generating high-quality, realistic data that closely mimics the characteristics of real phonocardiogram signals. This involves maintaining waveform fidelity, ensuring temporal consistency, and avoiding artifacts that may distort the signal. The study highlights that even advanced generative models like WaveNet, DoppelGANger, and DiffWave face difficulties in achieving this, as evidenced by evaluation metrics such as JSD and MMD, which show that synthetic data must be very close to real data to be considered effective. Additionally, the synthesis process requires careful handling of time-frequency transformations and multi-scale sub-signal fusion, as seen in ECG signal generation, which can be similarly applied to PCG signals. While specific PCG data is not shown in all cases, the general principles suggest that these challenges are inherent in creating synthetic cardiac signals.\"\n",
      "}\n",
      "======================\n",
      "=== AGENT REASONING ===\n",
      "Decision: answer\n",
      "Rationale: Despite fragmented evidence, the core intent of the question is addressed by the retrieved texts, which collectively highlight the challenges in generating realistic and high-quality PCG signals, including maintaining waveform fidelity, avoiding artifacts, and ensuring similarity to real data.\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# === Cell 10: Run Agent ===\n",
    "\n",
    "from functions.agent_ui import launch_agent_ui\n",
    "\n",
    "ui = launch_agent_ui(agent)\n",
    "ui.launch(inline=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
