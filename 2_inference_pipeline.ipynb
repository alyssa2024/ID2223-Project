{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75a9c7f",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9836097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Imports ===\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hopsworks\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HF_API_KEY\"] = \"\"\n",
    "os.environ[\"SILICONFLOW_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1113fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 23:08:48,735 INFO: Initializing external client\n",
      "2026-01-11 23:08:48,737 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-11 23:08:50,440 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286333\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Connect to Hopsworks ===\n",
    "\n",
    "from config import HOPSWORKS_API_KEY\n",
    "# project = hopsworks.login()\n",
    "\n",
    "project = hopsworks.login(\n",
    "        # project=HOPSWORKS_PROJECT,\n",
    "        api_key_value=HOPSWORKS_API_KEY\n",
    "    )\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b12dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Load Feature Views ===\n",
    "\n",
    "metadata_fv = fs.get_feature_view(\n",
    "    name=\"paper_metadata_fv_2\",\n",
    "    version=3,\n",
    ")\n",
    "\n",
    "chunk_fv = fs.get_feature_view(\n",
    "    name=\"paper_chunk_fv_2\",\n",
    "    version=3,\n",
    ")\n",
    "\n",
    "metadata_fv.init_serving(1)\n",
    "chunk_fv.init_serving(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf9e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 23:09:00,502 INFO: Use pytorch device_name: cpu\n",
      "2026-01-11 23:09:00,504 INFO: Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: Load Embedding Model ===\n",
    "sentence_transformer = SentenceTransformer(\n",
    "    config.EMBEDDING_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2c31d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2...\n",
      "2026-01-11 23:09:03,569 INFO: Use pytorch device: cpu\n",
      "Caching paper titles from Metadata Feature View...\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.09s) \n",
      "Successfully cached 17 titles.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5: Similarity Search Engine ===\n",
    "\n",
    "# from functions.similarity_search import SimilaritySearchEngine\n",
    "from functions.similarity_search_new import SimilaritySearchEngine\n",
    "\n",
    "search_engine = SimilaritySearchEngine(\n",
    "    embedding_model=sentence_transformer,\n",
    "    metadata_feature_view=metadata_fv,\n",
    "    chunk_feature_view=chunk_fv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5cf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Context Builder ===\n",
    "\n",
    "from functions.context_builder import ContextBuilder\n",
    "\n",
    "context_builder = ContextBuilder(\n",
    "    max_tokens=2000,\n",
    "    max_chunks=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f7e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Prompt Synthesizer ===\n",
    "\n",
    "from functions.prompt_synthesis import PromptSynthesizer\n",
    "prompt_synthesizer = PromptSynthesizer()\n",
    "\n",
    "# from functions.prompt_synthesis_debug import DebugPromptSynthesizer\n",
    "\n",
    "# prompt_synthesizer = DebugPromptSynthesizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29faaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: MCP Dispatcher ===\n",
    "\n",
    "from functions.mcp_dispatcher import MCPDispatcher\n",
    "\n",
    "mcp_dispatcher = MCPDispatcher(\n",
    "    search_engine=search_engine\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e0c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: Agentic Inference ===\n",
    "\n",
    "from functions.agent_loop import AgenticInference\n",
    "from functions.llm_wrapper import LLMWrapper  \n",
    "\n",
    "# llm = LLMWrapper(\n",
    "#     model_name_or_path=\"mistralai/Mistral-7B-v0.1\"  \n",
    "# )# local llm\n",
    "llm = LLMWrapper(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    base_url=\"http://api.siliconflow.cn/v1/\",\n",
    "    api_key=os.getenv(\"SILICONFLOW_API_KEY\"),\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "agent = AgenticInference(\n",
    "    llm=llm,\n",
    "    search_engine=search_engine,\n",
    "    context_builder=context_builder,\n",
    "    prompt_synthesizer=prompt_synthesizer,\n",
    "    mcp_dispatcher=mcp_dispatcher,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb23e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "2026-01-11 23:09:10,603 INFO: HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2026-01-11 23:09:10,631 INFO: HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 23:09:11,047 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2026-01-11 23:09:18,047 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-11 23:09:20,252 INFO: HTTP Request: POST http://api.siliconflow.cn/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== DETECTED INTENT: GREETING ===\n",
      "2026-01-11 23:09:22,007 INFO: HTTP Request: POST http://api.siliconflow.cn/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-11 23:09:31,225 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n",
      "2026-01-11 23:09:32,420 INFO: HTTP Request: POST http://api.siliconflow.cn/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== DETECTED INTENT: RAG_SEARCH ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f14f36d23f430e94fd589a3ad10a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9521b2d8b0174d6d98ce76cb62ce7f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d650a21aa948a28da3c73f95fd8d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAPER METADATA: {'T55ZK2Y7': {'title': 'PCG Signal Acquisition and Classification for Heart Failure Detection: Recent Advances and Implementation of Memory-Efficient Classifiers for Edge Computing-Based Wearable Devices', 'abstract': 'Conventional diagnostic tools for cardiovascular diseases usually employ expensive instrumentation and require specialized medical staff. An inexpensive and non-invasive alternative is the phonocardiogram (PCG). This paper presents the development of classifiers for binary (Normal/Pathological) and multiclass classifications of PCG signals. The latter discerns between a subset of heart diseases (mitral valve prolapse (MVP), coronary disease (CAD), and benign murmurs (Benign)). Two balanced datasets were created from the Physionet 2016/CinC database, consisting of 10104 and 13136 5-s frames. A custom preprocessing chain includes denoising, normalizing, and splitting the PCG signals, making them suitable to extract the scalar features set, constituting the training and test set. Several ML/DL models (e.g., SVMs (Support Vector Machines), k-NNs (k-Nearest Neighbors), and NNs (Neural Networks)) were trained and tested to classify the PCG signals. For binary classification, three different NNs have reached 96.0%, 95.9%, and 93.4% accuracy, and 95.9%, 96.0%, and 93.3% F1-scores, respectively. However, k-NN classifiers provide higher accuracy (up to 98.7%) than NNs but require much larger memory (up to 11 MB). As for the multiclass classification, three custom NNs have achieved 96.0%, 95.8%, and 94.7% accuracy with 735 kB max memory occupation. The developed classifiers provide a good balance between complexity and performance, with the latter not dependent on signal quality. In the feature engineering phase, the heart sound segmentation was not performed to make the classifiers suitable for resource-limited platforms.'}, 'IZB6XZRC': {'title': 'Synthetic Time Series Data Generation for Healthcare Applications: A PCG Case Study', 'abstract': 'The generation of high-quality medical time series data is essential for advancing healthcare diagnostics and safeguarding patient privacy. Specifically, synthesizing realistic phonocardiogram (PCG) signals offers significant potential as a cost-effective and efficient tool for cardiac disease pre-screening. Despite its potential, the synthesis of PCG signals for this specific application received limited attention in research. In this study, we employ and compare three state-of-the-art generative models from different categories — WaveNet, DoppelGANger, and DiffWave — to generate high-quality PCG data. We use data from the George B. Moody PhysioNet Challenge 2022. Our methods are evaluated using various metrics widely used in the previous literature in the domain of time series data generation, such as mean absolute error and maximum mean discrepancy. Our results demonstrate that the generated PCG data closely resembles the original datasets, indicating the effectiveness of our generative models in producing realistic synthetic PCG data. In our future work, we plan to incorporate this method into a data augmentation pipeline to synthesize abnormal PCG signals with heart murmurs, in order to address the current scarcity of abnormal data. We hope to improve the robustness and accuracy of diagnostic tools in cardiology, enhancing their effectiveness in detecting heart murmurs.'}, 'BX8G68KQ': {'title': 'A Comprehensive Overview of Heart Sound Analysis Using Machine Learning Methods', 'abstract': 'Cardiovascular diseases (CVDs) are a prevalent cause of mortality worldwide, and the traditional cardiovascular disease diagnosis has relied heavily on stethoscope-based heart sound auscultations. Hence, the development of medical systems has led to several machine learning (ML)-related studies for analysing heart sounds using phonocardiograms (PCGs). Although this process enables the detection of additional mechanical activity information about the heart muscle, various crucial gaps (background noise, unbalanced datasets, and irrelevant extracted features) are still observed. Therefore, this review examined the advancements in diagnosing heart sounds using ML-based PCG signal analysis. The evaluation process involved three datasets in the past five years (2019–2024): the PhysioNet/Computing in Cardiology (CinC) Challenge (2016–2022) and the Yaseen Khan 2018 datasets. This review also comprehensively explained the importance of heart sounds in cardiovascular disease diagnosis. Moreover, these studies demonstrated an overview of the most effective methods in handling datasets, pre-processing of PCG signals (filtering, segmentation, and normalisation), PCG signal processing techniques (feature extraction and feature selection), and machine learning models (classification). Several directions concerning heart sound diagnosis for future studies are then presented, which can serve as a reference point for diagnosing cardiovascular diseases.'}, 'R7JAHFY6': {'title': 'ECG Generation Based on Denoising Diffusion Probabilistic Models', 'abstract': 'Arrhythmia diseases seriously damage people’s life and health, and identifying abnormal points in ECG signals by deep neural networks is an effective method for detecting arrhythmias. However, their accuracy is often limited by the biased data distribution of the training set, and a large number of labeled ECG signals are usually harder to obtain. Therefore, this paper proposes to synthesize virtual heart beat data by denoising diffusion probability model (DDPM) based on the MIT-BIH arrhythmia database to complement the real data. Three different methods for generating heartbeat signals are also used, which are (i) generating heartbeat signals directly, (ii) generating time-frequency maps of heartbeats and transforming them into heartbeat signals, and (iii) generating sub-signals of heartbeats and fusing them into complete heartbeat signals. Regarding the evaluation of the synthesized signals, we compare the advantages and disadvantages of the three heartbeat generation methods by four metrics: DTW, PCC, ED and KLD. The experimental results showed that the optimum values of 4.37, 17.09, 0.972 and 0.0094 were obtained for ED, DTW of method (i) and PCC, KLD of method (iii), respectively.'}, 'WBP9IWFM': {'title': 'PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals', 'abstract': 'Abstract               —The newly inaugurated Research Resource for Complex Physiologic Signals, which was created under the auspices of the National Center for Research Resources of the National Institutes of Health, is intended to stimulate current research and new investigations in the study of cardiovascular and other complex biomedical signals. The resource has 3 interdependent components. PhysioBank is a large and growing archive of well-characterized digital recordings of physiological signals and related data for use by the biomedical research community. It currently includes databases of multiparameter cardiopulmonary, neural, and other biomedical signals from healthy subjects and from patients with a variety of conditions with major public health implications, including life-threatening arrhythmias, congestive heart failure, sleep apnea, neurological disorders, and aging. PhysioToolkit is a library of open-source software for physiological signal processing and analysis, the detection of physiologically significant events using both classic techniques and novel methods based on statistical physics and nonlinear dynamics, the interactive display and characterization of signals, the creation of new databases, the simulation of physiological and other signals, the quantitative evaluation and comparison of analysis methods, and the analysis of nonstationary processes. PhysioNet is an on-line forum for the dissemination and exchange of recorded biomedical signals and open-source software for analyzing them. It provides facilities for the cooperative analysis of data and the evaluation of proposed new algorithms. In addition to providing free electronic access to PhysioBank data and PhysioToolkit software via the World Wide Web (http://www.physionet.org), PhysioNet offers services and training via on-line tutorials to assist users with varying levels of expertise.'}}\n",
      "=== CONTEXT BUNDLE ===\n",
      "{'items': [{'source_id': 'BX8G68KQ#chunk-3', 'paper_id': 'BX8G68KQ', 'title': 'A Comprehensive Overview of Heart Sound Analysis Using Machine Learning Methods', 'content': 'Meanwhile, the diastolic phase is the distance between S2 and S1, in which the heart muscles relax and oxygenated blood is refilled into the left ventricle [5], [6]. These heart sounds can then be recorded as phonocardiogram (PCG) signals. The PCG signals are considered significant and high-energy signals among multiple vital signals for cardiac disease detection [7]. Therefore, heart sound analysis can enable the early detection of abnormal cardiac conditions, aiding in the early initiation of appropriate medical interventions [8], [9]. Even VOLUME 12, 2024 2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ 117203', 'score': -6.446521759033203}, {'source_id': 'T55ZK2Y7#chunk-3', 'paper_id': 'T55ZK2Y7', 'title': 'PCG Signal Acquisition and Classification for Heart Failure Detection: Recent Advances and Implementation of Memory-Efficient Classifiers for Edge Computing-Based Wearable Devices', 'content': 'The phonocardiogram (PCG), which utilizes the sounds generated by the cardiac mechanical activity to analyze the heart’s health, offers an affordable alternative to traditional non-invasive diagnostic tools. Various heart conditions, such as valvular heart disease, congenital heart disease, heart failure, high blood pressure, and coronary artery disease, can be detected via the auscultation and interpretation of the heart sounds [2]. In addition, the recent development of electronic stethoscopes made computer-assisted auscultation easy via the involvement of custom-designed sensors and machine learning (ML) or deep learning (DL) algorithms [3]. Also, wearable devices enable discreet and reliable monitoring of patient conditions [4, 5]. Thus, the technologies above allow the development of powerful tools for diagnosing heart disease. The typical process of PCG signal classification involves denoising, segmentation, and classification. The first step is performed because PCG signals are susceptible to various noise sources [6, 7]. The segmentation phase consists of identifying the fundamental heart sounds (FHS), namely, “S1” and “S2”, and. additional sounds, including “S3” and “S4”, murmurs, and various clicks, which are more challenging to be identified and often indicate pathological conditions [8, 9]. “S1” occurs at the start of the systole, whereas “S2” occurs at the beginning of the diastole.', 'score': -6.127883434295654}, {'source_id': 'BX8G68KQ#chunk-7', 'paper_id': 'BX8G68KQ', 'title': 'A Comprehensive Overview of Heart Sound Analysis Using Machine Learning Methods', 'content': 'Recent advances in portable electronic medical devices and PCG signal processing using ML techniques have facilitated the creation of intelligent, non-invasive, low-cost, and user-friendly tools. These tools can assist cardiologists in diagnosing cardiovascular diseases and their prediction at early stages [20]. Hence, PCG signals are crucial for describing the heart’s mechanical activities, which can be undetectable under ECG signals [21]. Table 1 tabulates the general differences between ECG and PCG [22], [23]. 117204 VOLUME 12, 2024', 'score': -5.436826705932617}, {'source_id': 'IZB6XZRC#chunk-0', 'paper_id': 'IZB6XZRC', 'title': 'Synthetic Time Series Data Generation for Healthcare Applications: A PCG Case Study', 'content': 'Synthetic Time Series Data Generation for Healthcare Applications: A PCG Case Study Ainaz Jamshidi Dept. of Information Systems University of Maryland Baltimore County, USA ainazj1@umbc.edu Muhammad Arif Dept. of Information Systems Colorado State University, USA muhammad.arif@csupueblo.edu Sabir Ali Kalhoro Dept. of Electrical Engineering North Dakota State University, USA Sabir13es66@gmail.com Alexander Gelbukh Dept. of Computing Research Center Instituto Polit´ecnico Nacional, Mexico gelbukh@cic.ipn.mx Abstract—The generation of high-quality medical time series data is essential for advancing healthcare diagnostics and safeguarding patient privacy. Specifically, synthesizing realistic phonocardiogram (PCG) signals offers significant potential as a cost-effective and efficient tool for cardiac disease pre-screening. Despite its potential, the synthesis of PCG signals for this specific application received limited attention in research. In this study, we employ and compare three state-of-the-art generative models from different categories — WaveNet, DoppelGANger, and DiffWave — to generate high-quality PCG data. We use data from the George B. Moody PhysioNet Challenge 2022. Our methods are evaluated using various metrics widely used in the previous literature in the domain of time series data generation, such as mean absolute error and maximum mean discrepancy.', 'score': -2.954678535461426}, {'source_id': 'T55ZK2Y7#chunk-13', 'paper_id': 'T55ZK2Y7', 'title': 'PCG Signal Acquisition and Classification for Heart Failure Detection: Recent Advances and Implementation of Memory-Efficient Classifiers for Edge Computing-Based Wearable Devices', 'content': '\\uf0b7 Machine and deep-learning models for the PCG signal classification. Several articles in the literature propose ML or DL algorithms to classify normal and abnormal PCG recordings or detect a specific cardiac disease. For instance, in ref. [19], the authors proposed a heart sound classifier to detect the presence of EICF (Exercise Induced Cardiac Fatigue) based on a residual network (ResNet), reaching an accuracy of 98.9% (98.9% precision and sensitivity). This algorithm achieves excellent performance thanks to wavelet denoising performed during preprocessing. Similarly, in ref. [20], a classifier based on a Support Vector Machine (SVM) was developed to discern between normal PCG signals and those with Coronary Artery Disease (CAD), which achieved a 90.9% accuracy. Also, in ref. [21], a CNN-based classifier was developed to automatically perform heart sound analysis for anomaly detection in scenarios with additive noise and sensordependent degradation. The classifier achieved an 85.1% balanced accuracy, 84.1% F1-score, and 0.9136 AUC (Area Under Curve). On the other hand, several ML or DL models were trained to detect the presence of different heart diseases, such as Aortic and Mitral Stenosis (AS and MS), Mitral Regurgitation (MR), Mitral Valve Prolapse (MVP), Extrasystole, and Murmurs. In ref.', 'score': -2.7150754928588867}, {'source_id': 'T55ZK2Y7#chunk-1', 'paper_id': 'T55ZK2Y7', 'title': 'PCG Signal Acquisition and Classification for Heart Failure Detection: Recent Advances and Implementation of Memory-Efficient Classifiers for Edge Computing-Based Wearable Devices', 'content': 'This paper presents the development of classifiers for binary (Normal/Pathological) and multiclass classifications of PCG signals. The latter discerns between a subset of heart diseases (mitral valve prolapse (MVP), coronary disease (CAD), and benign murmurs (Benign)). Two balanced datasets were created from the Physionet 2016/CinC database, consisting of 10104 and 13136 5-s frames. A custom preprocessing chain includes denoising, normalizing, and splitting the PCG signals, making them suitable to extract the scalar features set, constituting the training and test set. Several ML/DL models (e.g., SVMs (Support Vector Machines), k-NNs (k-Nearest Neighbors), and NNs (Neural Networks)) were trained and tested to classify the PCG signals. For binary classification, three different NNs have reached 96.0%, 95.9%, and 93.4% accuracy, and 95.9%, 96.0%, and 93.3% F1-scores, respectively. However, k-NN classifiers provide higher accuracy (up to 98.7%) than NNs but require much larger memory (up to 11 MB). As for the multiclass classification, three custom NNs have achieved 96.0%, 95.8%, and 94.7% accuracy with 735 kB max memory occupation. The developed classifiers provide a good balance between complexity and performance, with the latter not dependent on signal quality. In the feature engineering phase, the heart sound segmentation was not performed to make the classifiers suitable for resource-limited platforms.', 'score': -2.23528790473938}, {'source_id': 'T55ZK2Y7#chunk-4', 'paper_id': 'T55ZK2Y7', 'title': 'PCG Signal Acquisition and Classification for Heart Failure Detection: Recent Advances and Implementation of Memory-Efficient Classifiers for Edge Computing-Based Wearable Devices', 'content': 'additional sounds, including “S3” and “S4”, murmurs, and various clicks, which are more challenging to be identified and often indicate pathological conditions [8, 9]. “S1” occurs at the start of the systole, whereas “S2” occurs at the beginning of the diastole. Since PCG signals are not stationary, processing approaches in the time-frequency domain, including the Wavelet Transform (WT) or the ShortTime Fourier Transform (STFT), are very common [9, 10]. In this paper, the development of both binary (Normal/ Pathological) and multiclass PCG classifiers was deployed. The latter perceives several heart diseases, such as mitral valve prolapse (MVP), coronary disease (CAD), and benign murmurs (Benign). A portion of the Physionet/CinC 2016 was used to train and test classifiers. In detail, PCG signals were preprocessed, making them suitable for extracting a feature set belonging to the time, frequency, wavelet, and MFCC domains. Two balanced datasets were created to train and test the binary and multiclass models, consisting of 10104 and 13136 frames, from which 33 features were extracted. These lasts were used to test different ML/DL models (e.g., SVMs (Support Vector Machines), k-NNs (k-Nearest Neighbors), and NNs (Neural Networks)). For binary and multi-class classification, three feed-forward NNs provided better performance (up to 96.0% for accuracy and F1-score). Authorized licensed use limited to: KTH Royal Institute of Technology.', 'score': -2.0658457279205322}, {'source_id': 'BX8G68KQ#chunk-9', 'paper_id': 'BX8G68KQ', 'title': 'A Comprehensive Overview of Heart Sound Analysis Using Machine Learning Methods', 'content': 'This process encompasses filtering, segmentation, and normalisation methods. The PCG signals are typically recorded at low frequencies, which can be easily affected by various power disturbances. For example, noise can degrade the quality of the features, complicating the diagnosis process [10], [31]. A study by Prasad and Thalluri,. [32] observed that PCG signals possessed high sensitivity and low strength, which rendered them susceptible to noise interference. Therefore, filtering methods are necessary to remove unwanted noise from PCG signals. Generally, analogue (or digital)- based signal processing techniques are utilised to remove the noise [29]. This feature suggests that differential amplifiers and filters should be used to prevent interference [16]. For example, the Butterworth filters are the most prevalent techniques employed in literature for noise suppression, such as low band-pass [2], high band-pass [33], and band-pass filter [16]. A segmentation process involves dividing PCG signals into four segments: S1, systole, S2, and diastole (see Figure 2). This process extracts specific information for aiding the detection of normal and abnormal heart sounds [34]. Systole is the cardiac cycle phase when the heart muscle contracts, pushing blood out of the chambers into the arteries. The ventricles contract during this process, forcing blood into the pulmonary artery from the right ventricle and into the aorta from the left ventricle.', 'score': -2.057823896408081}], 'stats': {'num_items': 8, 'unique_papers': 3}, 'token_usage': {'estimated_tokens': 1391, 'max_tokens': 2000}}\n",
      "======================\n",
      "2026-01-11 23:09:41,970 INFO: HTTP Request: POST http://api.siliconflow.cn/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== RAW LLM OUTPUT ===\n",
      "{\n",
      "  \"decision\": \"answer\",\n",
      "  \"answer\": \"PCG signal refers to the signals recorded from the heart's mechanical activity, which can be used to analyze the heart's health and detect various cardiac conditions such as valvular heart disease, congenital heart disease, heart failure, high blood pressure, and coronary artery disease [2]. These signals are considered significant and high-energy among multiple vital signals for cardiac disease detection [1].\",\n",
      "  \"rationale\": \"The context explicitly defines PCG signals as recordings of the heart's mechanical activity and describes their importance in detecting cardiac conditions.\"\n",
      "}\n",
      "======================\n",
      "=== AGENT REASONING ===\n",
      "Decision: answer\n",
      "Rationale: None\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# === Cell 10: Run Agent ===\n",
    "\n",
    "from functions.agent_ui import launch_agent_ui\n",
    "\n",
    "ui = launch_agent_ui(agent)\n",
    "ui.launch(inline=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
