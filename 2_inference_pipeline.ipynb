{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75a9c7f",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9836097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Imports ===\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hopsworks\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1113fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:06:49,443 INFO: Initializing external client\n",
      "2026-01-08 02:06:49,443 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-08 02:06:51,077 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286333\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Connect to Hopsworks ===\n",
    "\n",
    "from config import HOPSWORKS_API_KEY\n",
    "# project = hopsworks.login()\n",
    "\n",
    "project = hopsworks.login(\n",
    "        # project=HOPSWORKS_PROJECT,\n",
    "        api_key_value=HOPSWORKS_API_KEY\n",
    "    )\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b12dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Load Feature Views ===\n",
    "\n",
    "metadata_fv = fs.get_feature_view(\n",
    "    name=\"paper_metadata_fv\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "chunk_fv = fs.get_feature_view(\n",
    "    name=\"paper_chunk_fv\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "metadata_fv.init_serving(1)\n",
    "chunk_fv.init_serving(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf9e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:07:05,063 INFO: Use pytorch device_name: cpu\n",
      "2026-01-08 02:07:05,064 INFO: Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: Load Embedding Model ===\n",
    "sentence_transformer = SentenceTransformer(\n",
    "    config.EMBEDDING_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b2c31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: Similarity Search Engine ===\n",
    "\n",
    "from functions.similarity_search import SimilaritySearchEngine\n",
    "\n",
    "search_engine = SimilaritySearchEngine(\n",
    "    embedding_model=sentence_transformer,\n",
    "    metadata_feature_view=metadata_fv,\n",
    "    chunk_feature_view=chunk_fv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5cf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Context Builder ===\n",
    "\n",
    "from functions.context_builder import ContextBuilder\n",
    "\n",
    "context_builder = ContextBuilder(\n",
    "    max_tokens=2000,\n",
    "    max_chunks=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f7e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Prompt Synthesizer ===\n",
    "\n",
    "from functions.prompt_synthesis import PromptSynthesizer\n",
    "\n",
    "prompt_synthesizer = PromptSynthesizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29faaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: MCP Dispatcher ===\n",
    "\n",
    "from functions.mcp_dispatcher import MCPDispatcher\n",
    "\n",
    "mcp_dispatcher = MCPDispatcher(\n",
    "    search_engine=search_engine\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0c365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beacc48dd62447797fa581ca1cd1298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:07:49,503 WARNING: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
      "\n",
      "2026-01-08 02:07:49,505 WARNING: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:07:49,804 WARNING: Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1dc648c0ae415fabd940ae56701897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1300ed47b83046569dc3c4163b53c222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32ecf6aa4c446d0b06e59d28b80c3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b33aee853943b7b4c4bd44329d7653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa0d029d28e4e23bbdd089c24ccf654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8e4e06c7f64bb482d2d2e9c18472a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:07:52,900 WARNING: Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:07:52,905 WARNING: Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0220fa387546dc89ef9acc4e8ca14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36989f738735475688e1600861fbbf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 9: Agentic Inference ===\n",
    "\n",
    "from functions.agent_loop import AgenticInference\n",
    "from functions.llm_wrapper import LLMWrapper  \n",
    "\n",
    "llm = LLMWrapper(\n",
    "    model_name_or_path=\"mistralai/Mistral-7B-v0.1\"  \n",
    ")\n",
    "\n",
    "agent = AgenticInference(\n",
    "    llm=llm,\n",
    "    search_engine=search_engine,\n",
    "    context_builder=context_builder,\n",
    "    prompt_synthesizer=prompt_synthesizer,\n",
    "    mcp_dispatcher=mcp_dispatcher,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb23e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 10: Run Agent ===\n",
    "\n",
    "query = \"What are the best risk reporting practices?\"\n",
    "\n",
    "answer = agent.run(query)\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
