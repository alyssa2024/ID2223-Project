{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75a9c7f",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9836097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Imports ===\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hopsworks\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HF_API_KEY\"] = \"\"\n",
    "os.environ[\"SILICONFLOW_API_KEY\"] = \"sk-rrswmweoulftfoccukdcuvyrlvbtblbufvhtvmrivwrcguaz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1113fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 18:32:14,661 INFO: Initializing external client\n",
      "2026-01-11 18:32:14,661 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-11 18:32:16,330 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286333\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Connect to Hopsworks ===\n",
    "\n",
    "from config import HOPSWORKS_API_KEY\n",
    "# project = hopsworks.login()\n",
    "\n",
    "project = hopsworks.login(\n",
    "        # project=HOPSWORKS_PROJECT,\n",
    "        api_key_value=HOPSWORKS_API_KEY\n",
    "    )\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b12dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Load Feature Views ===\n",
    "\n",
    "metadata_fv = fs.get_feature_view(\n",
    "    name=\"paper_metadata_fv_2\",\n",
    "    version=2,\n",
    ")\n",
    "\n",
    "chunk_fv = fs.get_feature_view(\n",
    "    name=\"paper_chunk_fv_2\",\n",
    "    version=2,\n",
    ")\n",
    "\n",
    "metadata_fv.init_serving(1)\n",
    "chunk_fv.init_serving(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf9e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 18:32:25,994 INFO: Use pytorch device_name: cpu\n",
      "2026-01-11 18:32:26,000 INFO: Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: Load Embedding Model ===\n",
    "sentence_transformer = SentenceTransformer(\n",
    "    config.EMBEDDING_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2c31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: Similarity Search Engine ===\n",
    "\n",
    "from functions.similarity_search import SimilaritySearchEngine\n",
    "\n",
    "search_engine = SimilaritySearchEngine(\n",
    "    embedding_model=sentence_transformer,\n",
    "    metadata_feature_view=metadata_fv,\n",
    "    chunk_feature_view=chunk_fv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5cf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Context Builder ===\n",
    "\n",
    "from functions.context_builder import ContextBuilder\n",
    "\n",
    "context_builder = ContextBuilder(\n",
    "    max_tokens=2000,\n",
    "    max_chunks=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f7e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Prompt Synthesizer ===\n",
    "\n",
    "from functions.prompt_synthesis import PromptSynthesizer\n",
    "prompt_synthesizer = PromptSynthesizer()\n",
    "\n",
    "# from functions.prompt_synthesis_debug import DebugPromptSynthesizer\n",
    "\n",
    "# prompt_synthesizer = DebugPromptSynthesizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29faaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8: MCP Dispatcher ===\n",
    "\n",
    "from functions.mcp_dispatcher import MCPDispatcher\n",
    "\n",
    "mcp_dispatcher = MCPDispatcher(\n",
    "    search_engine=search_engine\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e0c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: Agentic Inference ===\n",
    "\n",
    "from functions.agent_loop import AgenticInference\n",
    "from functions.llm_wrapper import LLMWrapper  \n",
    "\n",
    "# llm = LLMWrapper(\n",
    "#     model_name_or_path=\"mistralai/Mistral-7B-v0.1\"  \n",
    "# )# local llm\n",
    "llm = LLMWrapper(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    base_url=\"http://api.siliconflow.cn/v1/\",\n",
    "    api_key=os.getenv(\"SILICONFLOW_API_KEY\"),\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "agent = AgenticInference(\n",
    "    llm=llm,\n",
    "    search_engine=search_engine,\n",
    "    context_builder=context_builder,\n",
    "    prompt_synthesizer=prompt_synthesizer,\n",
    "    mcp_dispatcher=mcp_dispatcher,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb23e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "2026-01-11 18:32:32,377 INFO: HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2026-01-11 18:32:32,397 INFO: HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 18:32:32,805 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2026-01-11 18:33:19,411 WARNING: DeprecationWarning: 'HTTP_422_UNPROCESSABLE_ENTITY' is deprecated. Use 'HTTP_422_UNPROCESSABLE_CONTENT' instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf88e6614754badbaf0c59ecd286cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b13b41a3036412e8f958bdc9ac9cb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONTEXT BUNDLE ===\n",
      "{'items': [{'source_id': 'BX8G68KQ#chunk-7', 'paper_id': 'BX8G68KQ', 'content': 'For example, noise can degrade the quality of the features, complicating the diagnosis process [10], [31]. A study by Prasad and Thalluri,. [32] observed that PCG signals possessed high sensitivity and low strength, which rendered them susceptible to noise interference. Therefore, filtering methods are necessary to remove unwanted noise from PCG signals. Generally, analogue (or digital)- based signal processing techniques are utilised to remove the noise [29]. This feature suggests that differential amplifiers and filters should be used to prevent interference [16]. For example, the Butterworth filters are the most prevalent techniques employed in literature for noise suppression, such as low band-pass [2], high band-pass [33], and band-pass filter [16]. A segmentation process involves dividing PCG signals into four segments: S1, systole, S2, and diastole (see Figure 2). This process extracts specific information for aiding the detection of normal and abnormal heart sounds [34]. Systole is the cardiac cycle phase when the heart muscle contracts, pushing blood out of the chambers into the arteries. The ventricles contract during this process, forcing blood into the pulmonary artery from the right ventricle and into the aorta from the left ventricle. This phase is also measured from the beginning of ventricular contraction to the closure of the aortic and pulmonary valves. Alternatively, diastole is the cardiac cycle phase when the heart muscle relaxes and fills with blood.', 'score': 0.1111111111111111}, {'source_id': 'BX8G68KQ#chunk-10', 'paper_id': 'BX8G68KQ', 'content': 'M. F. A. B. Hamza, N. N. Amir Sjarif: Comprehensive Overview of Heart Sound Analysis B. FEATURE EXTRACTION The PCG features are independent variables of the heart sounds, functioning as input data for training ML models. Two processes are used for the data reduction process: feature extraction and feature selection. Feature extraction can improve PCG analysis procedures by providing more precise feature characterisation and lowering computing complexity [31]. This strategy also obtains essential and specific information about the functionality and changes in PCG signals. Given that the use conditions differ, the appropriate features are used depending on the system when analysing PCG signals [43]. A study by Rhif et al. [44] described a signal processing method consisting of two wavelet transform (WT) types: continuous wavelet transform (CWT) and discrete wavelet transform (DWT). Considering that the CWT method generates many wavelet coefficients for each scale, applying the CWT method to non-linear signals is challenging and time-consuming. The DWT method is advantageous due to its smaller number of coefficients. This method can effectively analyse non-stationary signals compared to the CWT method [45]. A study by Touahria et al. [46] suggested that the DWT method was suitable as it provided high classification performance and a more comprehensive representation of the features than the Mel-frequency cepstral coefficient (MFCC) method.', 'score': 0.125}, {'source_id': 'BX8G68KQ#chunk-5', 'paper_id': 'BX8G68KQ', 'content': 'The analysis determines the correlations between heart sounds and normal or abnormal heart conditions. Typically, conventional heart sound auscultation remains ineffective for diagnosing certain heart conditions due to the limitations of human hearing and the transient nature of heart sounds [18]. The clinical diagnosis of heart sounds is also problematic, requiring much practice and experience [19]. Recent advances in portable electronic medical devices and PCG signal processing using ML techniques have facilitated the creation of intelligent, non-invasive, low-cost, and user-friendly tools. These tools can assist cardiologists in diagnosing cardiovascular diseases and their prediction at early stages [20]. Hence, PCG signals are crucial for describing the heart’s mechanical activities, which can be undetectable under ECG signals [21]. Table 1 tabulates the general differences between ECG and PCG [22], [23]. 117204 VOLUME 12, 2024', 'score': 0.25}, {'source_id': 'T55ZK2Y7#chunk-9', 'paper_id': 'T55ZK2Y7', 'content': 'TABLE I summarizes the functionalities and features of sensors and systems for PCG signal acquisition described above. TABLE I. Summary of the functionalities and features related to sensors and systems for the PCG signals acquisition. Innovative sensors for PCG signal acquisition Reference Sensor type Sensitivity Bandwidth SNR T. Wang et al. [11] ECMs Array N.A. (*) N.A. (*) 29.36 dB J. Cui et al. [12] Cantilever beam bionic MEMS sensor -189.5 dB @ 500 Hz 10 − 800 Hz 29.08 dB P. Shi et al. [13] Cantilever beam bionic MEMS sensor -189.5 dB @ 500 Hz 20 − 600 Hz 25.62 dB Systems able to acquire also PCG signals Reference PCG sensor type Acquired signals/parameters Form factor S. Lee et al. [14] MEMS microphone PPG and PCG Foldable finger ring T.V. Nguyen et al. [15] Piezoresistive MEMS cantilever PCG and respiration signals Band-aid Y. Rong et al. [16] N.A.(*) PCG and ECG Wearable vest B. Guo et al. [17] MEMS microphone PCG and ECG Wearable vest M. Klum et al. [18] N.A.(*) PCG, ECG, LVET, and PEP Smart patch (*) N.A.: not available Authorized licensed use limited to: KTH Royal Institute of Technology. Downloaded on September 29,2025 at 17:43:26 UTC from IEEE Xplore. Restrictions apply.', 'score': 0.3333333333333333}], 'stats': {'num_items': 4, 'unique_papers': 2}, 'token_usage': {'estimated_tokens': 776, 'max_tokens': 2000}}\n",
      "======================\n",
      "2026-01-11 18:33:28,088 INFO: HTTP Request: POST http://api.siliconflow.cn/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== RAW LLM OUTPUT ===\n",
      "{\n",
      "  \"decision\": \"answer\",\n",
      "  \"answer\": \"PCG signal refers to the heart sound signals captured by medical devices, which are crucial for describing the heart’s mechanical activities. These signals can be used to detect normal and abnormal heart conditions and are often processed using machine learning techniques to improve diagnostic accuracy.\",\n",
      "  \"rationale\": \"The context explicitly describes PCG signals as essential for describing the heart’s mechanical activities and mentions their use in detecting normal and abnormal heart conditions, as well as their processing with ML techniques.\"\n",
      "}\n",
      "======================\n",
      "=== AGENT REASONING ===\n",
      "Decision: answer\n",
      "Rationale: None\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# === Cell 10: Run Agent ===\n",
    "\n",
    "from functions.agent_ui import launch_agent_ui\n",
    "\n",
    "ui = launch_agent_ui(agent)\n",
    "ui.launch(inline=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
